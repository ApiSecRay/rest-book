<chapter id="test">
  <title>Testing</title>
  <para>
    Now that you've implemented your API, you'll want to make sure that it works as expected. The most efficient way
    known today of doing that (when done right) is by testing. We define <firstterm>testing</firstterm> as checking
    against expectations.
  </para>
  <para>
    There are many different ways to test. Don’t exclusively rely on only one type of test, but reduce your overall
    risks by combining several types of tests. A classification of tests using the Ws may help with determining what
    types of tests are useful for your situation: 
  </para>
  <variablelist>
    <varlistentry>
      <term>Who</term>
      <listitem>
        <para>
          The first question to ask is whose expectations we are checking. There are at least two answers to that
          question: customers and developers, and so the Agile community talks about <firstterm>customer 
          tests</firstterm> and <firstterm>programmer tests</firstterm>.
        </para>
        <para>
          As every writer knows, the audience shapes the form his message must take. So we'll write programmer tests
          in a programming language and customer tests in a form that is accessible for non-developers, like Gherkin
          (see <xref linkend="bdd"/>).
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>What</term>
      <listitem>
        <para>
          In <xref linkend="non-functional-requirements"/>), we discussed the many qualities of software that matter in 
          addition to functionality. For each of those important qualities, you will want to check that your API
          implementation matches the expectations. So you'll have functional testing, performance testing, scalability
          testing, security testing, etc.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>When</term>
      <listitem>
        <para>
          Tests can be written after the code is finished to <emphasis>verify</emphasis> that it works, or 
          they can be written first to <emphasis>specify</emphasis> how the code should work. 
          Writing the test first may seem counter-intuitive or unnatural, but there are some advantages to this
          approach:
        </para>
        <itemizedlist>
          <listitem>
            <para>It guarantees that the code will be testable.</para>
          </listitem>
          <listitem>
            <para>It's more efficient to prevent bugs than to first introduce and then fix them</para>
          </listitem>
          <listitem>
            <para>
              Tests can be used to drive the design and implementation so that we´re never building more than required.
            </para>
          </listitem>
        </itemizedlist>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>Where</term>
      <listitem>
        <para>
          Tests can be written at different levels of abstraction
        </para>
        <itemizedlist>
          <listitem>
            <para>Unit tests test a single unit (e.g. class) in isolation.</para>
          </listitem>
          <listitem>
            <para>Integration tests focus on how the units work together.</para>
          </listitem>
          <listitem>
            <para>System tests look at the application as a whole.</para>
          </listitem>
        </itemizedlist>
        <para>
          As you move up the abstraction level from unit to system, you require fewer tests <citation>Test
          Pyramid</citation>. You may want to go even further and test a collection of applications that work together,
          for instance in a microservices architecture.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>Why</term>
      <listitem>
        <para>
          There can be different reasons for writing tests. All tests verify that the code works as expected, but we've
          also seen that tests can serve as specifications of how yet-to-be-written code should work. In the latter
          situation, the tests exists not only for verification, but also to facilitate communication about how the
          application should behave, as we've seen.
          Tests can also be written to drive the code and its design. This is called <firstterm>Test-Driven
          Design</firstterm> (TDD).
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term>How</term>
      <listitem>
        <para>
          Tests can be performed by a human or by a computer program. Manual testing is most useful in the form of
          <firstterm>exploratory testing</firstterm>, where a skilled tester uses his domain knowledge to explore all
          corners of the system. Most other forms of testing should be automated as much as possible.
        </para>
        <para>
          The amount of software you ship will usually grow over time as you add features, and your testing effort will
          do so as well. If you don’t automate your tests, you testing effort will grow until it starts getting in the
          way of making progress. Automation can keep the costs of testing down.
        </para>
        <para>
          Another aspect of <emphasis>how</emphasis> is whether the tests look into the system under test or whether
          they only use the public API. The former is called <firstterm>white-box</firstterm> testing; the latter is
          <firstterm>black-box</firstterm> testing.
        </para>
      </listitem>
    </varlistentry>
  </variablelist>
  <para>
    As even this short treatment shows, testing is a vast topic. We can only scratch the surface in this book, so we
    will focus only on those aspects of testing that are specific to testing APIs.
  </para>
  
  <section>
    <title>Functional Testing</title>
    <para>
      You will want to make sure your API implementation works as expected. You will also want to make sure that
      no change you introduce later will break existing functionality. And you most likely will want to start small
      and grow your system over time. Maybe you even want to iterate quickly based on feedback from your API's users.
      To meet all those requirements, you need to automate your tests.
    </para>
    <para>
      We hope you already have unit tests in place to white-box test your implementation. We also hope you have a
      Continuous Integration (CI) server in place, which runs the unit tests on every change to the code. The next step 
      is to create a suite of automated black-box tests against your API.
    </para>
    <para>
      While you certainly <emphasis>can</emphasis> write white-box tests at the API level, we suggest you write
      black-box tests instead (or in addition). The ultimate test of your system is that your clients can use the
      API, and they won't be able to see your system's internals. If your API isn't sufficient to make black-box testing
      possible, chances are that it isn't complete enough for some clients to do their work.
    </para>
    <para>
      If you started your analysis using Behavior-Driven Development (BDD), as we suggested in <xref linkend="analysis"/>,
      then you're already halfway to an automated black-box test suite. All you need to do is write some glue code that
      translates the BDD scenarios into HTTP calls against your server (<literal>Given</literal>
      and <literal>when</literal>) and that verifies the assertions (<literal>Then</literal>).
    </para>
    <para>
      If you don't have any BDD scenarios, then you'll need some other method of creating test specifications. The 
      details of what follows will be different, but the idea remains the same: make a series of calls into your API to 
      verify that the implementation matches expectations.
    </para>
    <para>
      It's very useful for debugging purposes to use a correlation ID (see <xref linkend="correlation"/>) so that the
      different requests and responses for a given test case can be related. This is otherwise non-trivial when you
      run tests in parallel (which you should to get quicker feedback). The test case name makes a good candidate as the
      value of the correlation ID.
    </para>
    <para>
      There are many BDD frameworks, depending on your programming environment. We only have room to show one here, and 
      we'll use Java and the JBehave framework <citation>JBehave</citation>. Other frameworks offer comparable features, 
      so even if your not using JBehave, or even Java, the following should still give you a good idea of how to proceed.
    </para>
    <para>
      JBehave makes it relatively easy to translate Gherkin scenarios into Java calls. For each line of the scenario,
      you must create a Java method that gets executed when the scenario parser processes the line. Let's see how that
      works using <xref linkend="bdd-customer-happy-path"/>.
    </para>
    <para>
      The first line is <literal>Given a customer Chrissy</literal>. Remember that each line starts with a keyword,
      in this case <literal>Given</literal>. JBehave has an annotation for each keyword, which helps the scenario
      parser map the line to a Java method using the text inside the annotation: 
    </para>
    <programlisting>public class RestbuckSteps {
    
  private String customer;

  @Given("a customer $customer")
  public void setCustomer(String customer) {
    this.customer = customer;
  }
  
}</programlisting>
    <para>
      A scenario line consists of fixed and variable parts. The variable parts are prefixed with the
      <literal>$</literal> sign and mapped to arguments of the Java method via a form of pattern matching much like. 
      In the example above, that is the case for the name of the customer. We either need that information in the
      method itself, or we save it for later use, for instance when we're verifying expectations.
    </para>
    <para>
      Parameterizing methods like this means we can write another scenario with a line like <literal>Given a customer
      Joe</literal>, and we wouldn't need a new method to match it. As you add more scenarios, you'll find that most
      lines in them can already be matched by existing methods, so your testing effort actually
      <emphasis>decreases</emphasis> over time!
    </para>
    <para>
      The next line is <literal>When she reads the menu</literal>, for which we add a method using the
      <literal>When</literal> annotation:
    </para>
    <programlisting>@When("she reads the menu")
public void getMenu() {
  resource = client.get(Api.LINK_REL_MENU).toObject(MenuResource.class);
}</programlisting>
    <para>
      Here we use the <literal>client</literal> object to issue a <literal>GET</literal> request on the URI found by
      following the link relation defined by the constant <literal>Api.LINK_REL_MENU</literal>. Remember from
      <xref linkend="controller"/> that the <literal>Api</literal> class contains constants for various components that 
      make up the API, like link relations. The server team publishes the <literal>Api</literal> class so client teams
      can consume it.
    </para>
    <para>
      The <literal>toObject()</literal> method in the above code converts the response to an instance of the
      <literal>MenuResource</literal> class. This is the same Data Transfer Object (DTO) that the server uses and can
      also be published by the server team. Alternatively, the server team can publish their API description (see
      <xref linkend="radl"/>) and the client team can generate the appropriate DTO classes for their development 
      environment (which may be different than the server team's).
    </para>
    <para>
      Remember from <xref linkend="server-arch"/> that converting a request or response into a DTO is the responsibility 
      of a message converter. You will need message converters on the client for the media type(s) that the client wants 
      to use, which may be a subset of the media types the server supports.
    </para>
    <para>
      If client and server are implemented using the same progamming language and HTTP framework, then they may share 
      the same libraries of message converters, but that is by no means a requirement. The goal of the REST 
      architectural style is loose coupling, and it's perfectly fine to use a different HTTP framework or even
      programming language on the client than on the server. Each team gets to make the best choice for their specific 
      context.
    </para>
    <para>
      The above code looks into the response for the menu link relation, which implies that at least one request must
      have been made. This is the request that jumpstarts every client, so it is performed as soon as the test class is
      created:
    </para>
    <programlisting>private ResourceSupport resource;
private final Client client = new Client(BILLBOARD_URI, 
    Api.DEFAULT_MEDIA_TYPE);</programlisting>
    <para>
      The <literal>Client</literal> class is responsible for communicating with the server. We tell it the server's
      billboard URI so that it can retrieve a representation of the home resource, as depicted in
      <xref linkend="client-flow"/>. We'll come back to the <literal>Client</literal> class in the next section, but
      let's finish the scenario first.
    </para>
    <para>
      The next line of the scenario places an order:
    </para>
    <programlisting>@When("she orders a $drink")
public void order(String drink) {
  ItemResource item = parseItem(drink);
  ItemResource result = findMenuItem(item);
  assertNotNull("Item not on the menu: " + item.name, result);

  OrderResource order = new OrderResource();
  order.customer = customer;
  order.items = new ItemResource[] { item };
  resource = client.post(order, Api.LINK_REL_ORDERACTION)
      .toObject(OrderResource.class);
}

private ItemResource parseItem(String drink) {
  ItemResource item = new ItemResource();
  String[] parts = drink.split("\\s+");
  item.size = parts[0];
  item.milk = parts[1];
  
  Assert.assertEquals("No milk in drink", "milk", parts[2]);
  item.name = parts[3] + ' ' + parts[4];
  return item;
}

private ItemResource findMenuItem(ItemResource item) {
  MenuResource menu = (MenuResource)resource;
  if (menu == null || menu.items == null) {
    return null;
  }
  for (ItemResource candidate : menu.items) {
    if (candidate.name.equals(item.name)) {
      return candidate;
    }
  }
  return null;
}</programlisting>
    <para>
      We parse the drink in the scenario line into its parts, so that we know what item to order. We then look through 
      the menu to find the item, create a order for the item, and place the order with the server. We use the customer's
      name that we saved earlier.
    </para>
    <programlisting>@Then("she is due $currency $total")
public void assertOrderTotal(String currency, double total) {
  assertCreated();
  OrderResource order = (OrderResource)resource;
  assertEquals("Total", total, order.total, 0.01);
  assertEquals("Currency", currency, order.currency);
}

private void assertCreated() {
  assertEquals("Status", 201, client.getStatusCode());
}</programlisting>
    <para>
      <literal>@Then</literal> methods typically check expectations through assertions. This is where your unit test
      framework comes in. We use plain JUnit here.
    </para>
    <programlisting>@When("she pays")
public void pay() {
  PaymentResource payment = paymentForOrder();
  paidAmount = payment.amount;
  paidCurrency = payment.currency;
  resource = client.post(payment, Api.LINK_REL_PAYACTION)
      .toObject(ReceiptResource.class);
}

private PaymentResource paymentForOrder() {
  OrderResource order = (OrderResource)resource;
  PaymentResource result = new PaymentResource();
  result.amount = order.total;
  result.currency = order.currency;
  result.paymentMethod = "creditcard";
  result.cardholderName = "C.C. Conway";
  result.cardNumber = "5525366617069778";
  result.expiryYear = 2019;
  result.expiryMonth = 6;
  result.cardSecurityCode = "836";
  return result;
}</programlisting>
    <para>
      Here we hard-coded the credit card details, which makes the step less resuable. Don't worry about that too much;
      as soon as you get more scenarios you can generalize the code. The code remembers how much to pay, so that it can 
      verify the receipt:
    </para>
    <programlisting>@Then("she is handed a receipt")
public void assertReceipt() {
  assertCreated();
  ReceiptResource receipt = (ReceiptResource)resource;
  assertEquals("Currency", paidCurrency, receipt.currency);
  assertEquals("Total", paidAmount, receipt.total, 0.01);
  assertEquals("Shop", "RESTBucks", receipt.shop);
}</programlisting>
    <para>
      It gets a little bit more interesting in the next step, when the customer has to wait for the barista to prepare
      her order:
    </para>
    <programlisting>@When("she takes the receipt")
public void takeReceipt() {
  resource = client.get(Api.LINK_REL_ORDER)
      .toObject(OrderResource.class);
}

@Then("she must wait for the barista")
public void waitForServing() {
  long start = System.currentTimeMillis();
  while (isPreparing()) {
    assertTrue("Waited too long for serving", 
        System.currentTimeMillis() - start > MAX_WAIT_TIME);
    waitAWhile();
  }
}

private boolean isPreparing() {
  return !resource.hasLink(Api.LINK_REL_RESPONDACTION);
}

private void waitAWhile() {
  try {
    Thread.sleep(INCREMENTAL_WAIT_TIME);
  } catch (InterruptedException e) {
    throw new RuntimeException(e);
  }
  resource = client.get(Api.LINK_REL_SELF)
      .toObject(OrderResource.class);
}</programlisting>
    <para>
      Remember that we implemented the barista's notification to the customer using polling, which is nothing more then
      repeatedly refreshing the representation until a link appears that lets us continue (see
      <xref linkend="polling"/>). Here's the remainder of the scenario implementation:
    </para>
    <programlisting>@When("the barista calls her name")
public void served() {
  resource = client.get(Api.LINK_REL_RESPONDACTION)
      .toObject(ServingResource.class);
}

@Then("her serving is ready")
public void assertServing() {
  assertTrue("Missing link",
      resource.hasLink(Api.LINK_REL_RECEIVEACTION));
}

@When("she takes her serving")
public void takeServing() {
  resource = client.delete(Api.LINK_REL_RECEIVEACTION)
      .toObject(ResourceSupport.class);
}

@Then("she is happy")
public void end() {
  // Nothing to do
}</programlisting>
    <para>
      Note that in the above code the client explicitly selects the HTTP methods to use, using
      <literal>client.get()</literal>, <literal>client.post()</literal>, etc. This is the way to go if the server 
      doesn't include this information in its responses. If the server uses a more mature media type like JSON-LD with
      Hydra, then the client can refrain from hard-coding the HTTP methods. In that case, the <literal>Client</literal>
      class would offer a generic <literal>follow()</literal> method that would retrieve the correct HTTP method from
      the response.
    </para>
    <para>
      Tests prove that your code works as expected and prevent regressions from entering production. Since they
      capture expectations, they must be updated when those expectations change. IOW, breaking API changes may lead to 
      re-work in the tests. This is the same pain that the API users will experience when you change your API, so listen
      carefully to the pain and look for ways to ease it. We'll talk more about the relationship between testing and 
      making API changes in <xref linkend="consumer-contract"/>.
    </para>
  </section>

  <section id="sdk">
    <title>Building an SDK</title>
    <para>
      The test code you write is just that: code. Therefore the same considerations apply as for the code that
      implements your API. You'll need to evolve your tests over time just like you need to evolve your implementation, 
      and it pays to treat your test code with the same care. In particular, keep your test code as DRY (see 
      <xref linkend="controller"/>) as your implementation code. That will make it much less painful to change your
      tests later.
    </para>
    <para>
      Since the tests exercise your API, they are in fact a client of it. Keeping your test code DRY has the interesting 
      side effect of building up a <firstterm>Software Development Kit</firstterm> (SDK) for your API. Remember from 
      <xref linkend="dx"/> that offering an SDK is a good way to improve the DX.
    </para>
    <para>
      The <literal>Client</literal> class from the previous section can be seen as the core of an SDK. As you implement
      more scenarios, you'll see common patterns of how you are using the API and thus the <literal>Client</literal>
      class. Extract common code into methods and classes and move those into the SDK. The SDK will slowly move away
      from low-level details like HTTP methods and link relations towards business domain processes.
    </para>
    <para>
      Since the tests play the role of API client, they should follow the guidelines for clients presented in 
      <xref linkend="client"/>. As you write your tests, you're effectively doing what client developers would be doing.
      This gives you a sense of what it's like to use the API. You may even decide to change the API based on this
      feedback to make it friendlier to use.
    </para>
    <para>
      For a good and quick feedback cycle, you will want to keep your Continuous Integration jobs fast. So if you make
      the API tests part of your Continuous Integration pipeline, then you'll face pressure to keep the test times down.
      This pressure is your friend when it comes to building an SDK, because it will encourage you to introduce caching 
      and other performance tricks (see <xref linkend="performance"/>). Your SDK users will automatically benefit from
      this effort.
    </para>
    <para>
      The SDK you're building up when implementing your tests will be written in whatever language you have chosen for
      automating your tests. If some clients are not written in that language, you may have to spend some 
      additional effort to port your SDK to the languages that your API users (i.e. the developers that build clients) 
      want to use. This is additional work, but at least you'll have an existing SDK that you can start from.
    </para>
    <para>
      The SDK powers your functional tests, and hopefully delights your users. But it can do more. As discussed earlier,
      you will have different kinds of tests in addition to functional tests, like performance tests. These tests can
      obviously benefit from the SDK as well. Take this opportunity, because it will help you create an SDK that works
      for as many different usage patterns as possible.
    </para>
    <para>
      An SDK can make using an API easier by hiding implementation details, like the specifics of a certain HTTP client
      library. The client developer then doesn't need to learn how to use a HTTP library; he can simply make method
      calls. You have to be careful with this, however, so that you don't fall for any of the Fallacies of Distributed
      Computing <citation>Rotem06</citation>. Especially the first two (the network is reliable, latency is zero) will
      get you into trouble.
    </para>
    <para>
      Hiding implementation details can shield a client from breaking changes (see <xref linkend="breaking-changes"/>).
      Maybe you exchanged an extension link relation for a newly standardized one. The SDK can check for either and use
      the one that the server provides. This code can be hidden in the SDK's implementation, so that clients using the 
      SDK will never see any difference and don't need to be changed.
    </para>
    <para>
      SDKs can also lower the barrier to entry for your API. Package your SDK up in the native artifact format for the
      target programming language, like a .NET assembly or a Java jar. Then upload the package to a place where the
      standard package managers can find them, like NuGet or Maven Central. This allows client developers to get 
      started quickly, using idioms they already know. The faster they can get their <literal>Hello, world!</literal>
      equivalent running, the less likely are they to give up in frustration and abandon your API.
    </para>
    <para>
      You should put the SDKs on GitHub or an equivalent source code repository so they're easily found by client
      developers and easy for you to update. As a bonus, this invites client developers to submit bug fixes, or even
      ports of the SDK into a programming language that you don't currently support.
    </para>
    <para>
      At the time of writing, RADL has no tooling to generate SDKs, but it's not hard to conceive of such help.
      A big part of the SDK consists of following link relations and (de)serializing programming language objects 
      into HTTP messages. The API description contains all the information necessary to perform these tasks, so it's
      just a matter of putting the work in to build the tooling.
    </para>
  </section>
  
  <section id="test-security">
    <title>Security Testing</title>
    <para>
      You will want to verify that your system meets the expectations with regard to security as well as functionality.
      Remember from <xref linkend="security"/> that security problems split roughly evenly between design flaws and 
      implementation bugs. The first part of security testing deals with design flaws. This is really just testing the 
      system's security features, using the techniques for functional testing described above.
    </para>
    <para>
      Remember that we derived the system's security features during threat modeling.
      For example, <xref linkend="security-features"/> indicates that we want to use TLS to protect against spoofing
      the server. We should write a test that checks whether connecting to our server over HTTPS works. This test should
      verify the TLS protocol, ciphers, and the server's certificate. We should write another test that verifies that
      we can't connect to the server using plain HTTP.
    </para>
    <para>
      This is a common pattern for functional security tests: you write a positive test that verifies that the security
      feature is in place, but also a negative test that proves you can't get around the protection.
    </para>
    <para>
      Some tests may be difficult to perform, like tests for DoS protection. It may help to configure your server to
      facilitate testing. For instance, suppose that in production, we allow our order queue size to be at most 100.
      It may be difficult or expensive to reach those numbers in a test, so we should make the limit configurable and 
      use a much lower number in our test environment than we would in production.
    </para>
    <para>
      Externalizing such configuration from the code is a good practice <xref linkend="separate-config-from-code"/>
      that will make your life easier in the future when the settings needs to be changed for non-code related reasons
      like the deployment of more powerful hardware.
    </para>
    <para>
      Other security features may even be impossible to verify in a test environment. Maybe you're using a Hardware
      Security Module (HSM) in production for managing and safeguarding cryptographic keys and don't have budget to 
      purchase another one just for testing. Luckily, the features that are most expensive to replicate in a test 
      environment are usually also the least likely to change. So you can manually verify that they work before you
      launch and then periodically to verify they continue to do so.
    </para>
    <para>
      Some features may be too difficult for you to test because you lack the required security skills. You can opt to 
      outsource this testing to an external company that is specialized in these matters. This is known as a 
      <firstterm>penetration test</firstterm> or pentest.
      Obviously you can't do this in an automated fashion on every commit, so this shouldn't be your only option.
    </para>
    <para>
      Penetration testers are not cheap, but well worth the money. In some cases, they are virtually a must. For 
      instance, as a cloud service provider, you probably don't want every customer to go into your data center to
      perform an audit. You can still satisfy the customer's need to understand your security posture by handing them a
      report from a reputable pentesting company.
    </para>
    <para>
      Penetration testers can work with a black-box kind of approach, where they don't have much insight into your
      defenses, or you can provide them with as much detail as they want. The former gives them a level playing field
      with real-world attackers, but it may limit what they can find. Motivated attackers are likely to have a lot more 
      time to find holes than you're willing to pay pentesters. Therefore, we favor the white-box approach where
      the pentesters have access to architectural diagrams, the threat model, etc. Some companies even give pentesters
      access to source code.
    </para>
    <para>
      With access to source code, a pentester can perform <firstterm>Static Analysis Security Testing</firstterm> (SAST).
      This involves feeding the source code into a special program that understands the programming language and
      libraries used and can find security problems. These problems are usually implementation bugs rather than
      design flaws.
    </para>
    <para>
      There are also SAST tools that can look at compiled binaries rather than source code. This allows you to scan
      any third party code that you embed in addition to your own code. Verifying external code is part of a larger
      <firstterm>supply chain management</firstterm> effort that is becoming ever more important for securing systems.
      It is estimated that roughly 70% of vulnerabilities are now caused by third party code. This is not surprising,
      given the industry's increased reliance on open source.
    </para>
    <para>
      SAST tools are good at finding certain types of bugs that are very relevant for testing APIs, like the injection
      attacks we saw in <xref linkend="output-encoding"/>. Withstanding these attacks and other ones like them is not
      too hard using input validation and output encoding, but the trick is to judiciously apply them everywhere. An
      attacker needs only one hole to get in. SAST tools can help you find the places where you've missed something.
    </para>
    <para>
      You don't need a pentester to operate a SAST tool, of course. While some of these tools may have somewhat of a 
      learning curve, any good developer can master them. The next step is to integrate the SAST tool into your
      Continuous Integration pipeline. These tools can take a long time to run, so you may not want to do so on every
      commit, but rather once per day or week. 
    </para>
    <para>
      SAST tools do their magic without running the application. In contrast, <firstterm>Dynamic Application Security
      Testing</firstterm> (DAST) tools work against a running instance of your software. Like SAST, DAST finds mostly
      implementation bugs, but the types of bugs found are somewhat different. It therefore pays to perform both
      kinds of tests.
    </para>
    <para>
      DAST tools can either exercise your API directly, or they can sit as a proxy in between the client and server.
      The latter setup makes a lot of sense for integrating them into your Continuous Integration pipeline. An example
      of an open source tool that works well in such a configuration is Zed Attack Proxy <citation>ZAP</citation>.
    </para>
    <para>
      An interesting approach to security testing is <firstterm>BDD Security</firstterm>, which couples BDD with
      SAST tools like ZAP <citation>BDD Security</citation>. It thus unifies functional and security testing through
      a single technique and toolchain.
    </para>
    <para>
      BDD Security also comes with a set of predefined scenarios to test various security features that are common
      across applications. This is a nice application of the notion of an attack library that we discussed in
      <xref linkend="threat-modeling"/>.
    </para>
    <para>
      One special type of DAST tool may be interesting for testing APIs. <firstterm>Fuzz testing</firstterm>
      or <firstterm>fuzzing</firstterm> involves providing invalid, unexpected, or random data as input. This data is
      usually generated from valid input. The program is then monitored for exceptions such as crashes, or other
      unwanted behavior. This is a good way to verify the completeness of your input validation. Fuzz testing can 
      find odd oversights and defects which even careful human test designers would fail to create tests for.
    </para>
  </section>
  
  <section>
    <title>RADL Support During Testing</title>
    <para>
      The RADL tools can generate a dummy implementation of the server that implements the REST design as captured in
      the API description. This implementation is functional in the sense that it implements all the methods on all
      the resources, but it obviously doesn't contain the correct business logic. It returns mostly empty responses, 
      and ignores any input sent by a client.
    </para>
    <para>
      Nevertheless, this can be helpful when implementing any client, including a test. The test can issue its requests 
      and inspect the responses. Any validations on those responses will fail, of course, since the server isn't really
      implemented yet, but at least the tests can be written and verified to interact correctly with the server. This is
      particularly helpful when writing the tests before the server is complete.
    </para>
    <para>
      We can go a step further by adding examples to the API description. Remember that a RADL
      <literal>property-group</literal> describes the data that is transferred between client and server. You can add
      example values for the properties in a <literal>property-group</literal> and those will then be used by the
      generated dummy implementation. If you're using BDD, then you can simply use the examples from the scenarios.
    </para>
    <para>
      There is also help for testing the server. You can add usage scenarios, like BDD scenarios, to RADL and the
      tooling can generate the BDD stories and JBehave steps to implement them. You can also start with BDD scenarios
      and generate the RADL usage scenarios. 
    </para>
  </section>
  
  <section>
    <title>Summary</title>
    <para>
      This chapter briefly explores how to test the API implementation for functional and security problems. After
      establishing that the implementation meets our expectations, we can deploy it into production and start running
      the service. This is the topic of the next chapter.
    </para>
  </section>
</chapter>
